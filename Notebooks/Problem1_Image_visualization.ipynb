{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import h5py\n",
    "import json\n",
    "import typing\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data/hdf5v5_16bit\")\n",
    "\n",
    "with open('pre_process_cfg_local.json', 'r') as fd:\n",
    "    pre_process_config = json.load(fd)\n",
    "\n",
    "hdf5_path = pre_process_config[\"hdf5_path\"]\n",
    "dataframe_path = pre_process_config[\"dataframe_path\"]\n",
    "stations = pre_process_config[\"stations\"]\n",
    "target_channels = [\"ch1\",\"ch2\",\"ch3\",\"ch4\",\"ch6\"]\n",
    "utils.viz_hdf5_imagery(hdf5_path, target_channels, dataframe_path, stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys(f):\n",
    "    return [key for key in f.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch1_data: (650, 1500)\n",
      "<HDF5 dataset \"BND_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"BND_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"DRA_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"DRA_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"FPK_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"FPK_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"GWN_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"GWN_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"PSU_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"PSU_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"SXF_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"SXF_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"TBL_GHI\": shape (96,), type \"<f8\">\n",
      "<HDF5 dataset \"TBL_GHI_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ch1\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ch1_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ch2\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ch2_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ch3\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ch3_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ch4\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ch4_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ch6\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ch6_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"lat\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"lat_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"lon\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"lon_LUT\": shape (96,), type \"<i4\">\n",
      "<HDF5 dataset \"ncdf_path\": shape (86,), type \"|O\">\n",
      "<HDF5 dataset \"ncdf_path_LUT\": shape (96,), type \"<i4\">\n",
      "==========\n",
      "compr_args\n",
      "compr_type\n",
      "force_cvt_uint16\n",
      "force_cvt_uint8\n",
      "orig_dtype\n",
      "orig_max\n",
      "orig_min\n",
      "orig_shape\n",
      "values:\n",
      "{}\n",
      "auto\n",
      "True\n",
      "False\n",
      "float32\n",
      "2.7549999\n",
      "-0.01\n",
      "[ 650 1500]\n",
      "==========\n",
      "compr_args\n",
      "compr_type\n",
      "force_cvt_uint16\n",
      "force_cvt_uint8\n",
      "orig_dtype\n",
      "orig_shape\n",
      "values:\n",
      "False\n",
      "False\n",
      "float32\n",
      "[650]\n"
     ]
    }
   ],
   "source": [
    "hdf5_offset = 33  # this would correspond to 2015.01.01.0800 + (32)*15min = 2015.01.01.1600\n",
    "with h5py.File(hdf5_path, 'r') as h5_data:\n",
    "    ch1_data = utils.fetch_hdf5_sample(\"ch1\", h5_data, hdf5_offset)\n",
    "    print(\"ch1_data:\",ch1_data.shape)\n",
    "    print(*list(h5_data.values()),sep = \"\\n\")\n",
    "    GHI = h5_data[\"BND_GHI\"][()]\n",
    "    ch1 = h5_data[\"ch1\"][()]\n",
    "    ch1_lut = h5_data[\"ch1_LUT\"][()]\n",
    "    lat = h5_data[\"lat\"][()]\n",
    "    lon = h5_data[\"lon\"][()]\n",
    "    ch1_0 = utils.fetch_hdf5_sample(\"ch1\", h5_data, 0)\n",
    "    lat_0 = utils.fetch_hdf5_sample(\"lat\", h5_data, 0)\n",
    "    print(\"==========\")\n",
    "    print(*list(h5_data[\"ch1\"].attrs),sep = \"\\n\")\n",
    "    print(\"values:\")\n",
    "    print(h5_data[\"ch1\"].attrs[\"compr_args\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"compr_type\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"force_cvt_uint16\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"force_cvt_uint8\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"orig_dtype\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"orig_max\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"orig_min\"])\n",
    "    print(h5_data[\"ch1\"].attrs[\"orig_shape\"])\n",
    "    print(\"==========\")\n",
    "    print(*list(h5_data[\"lat\"].attrs),sep = \"\\n\")\n",
    "    print(\"values:\")\n",
    "    print(h5_data[\"lat\"].attrs[\"force_cvt_uint16\"])\n",
    "    print(h5_data[\"lat\"].attrs[\"force_cvt_uint8\"])\n",
    "    print(h5_data[\"lat\"].attrs[\"orig_dtype\"])\n",
    "    print(h5_data[\"lat\"].attrs[\"orig_shape\"])\n",
    "    #lat = h5_data[\"lat\"][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "ch1_data2 = np.around(ch1_data*255/(ch1_data.max()-ch1_data.min()))\n",
    "print(ch1_data2.min())\n",
    "print(ch1_data2.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"ch1.png\",ch1_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_path, 'r') as h5_data:\n",
    "    lats, lons = utils.fetch_hdf5_sample(\"lat\", h5_data, hdf5_offset),\\\n",
    "    utils.fetch_hdf5_sample(\"lon\", h5_data, hdf5_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('BND', [40.05192, -88.37309, 230]), ('TBL', [40.12498, -105.2368, 1689]), ('DRA', [36.62373, -116.01947, 1007]), ('FPK', [48.30783, -105.1017, 634]), ('GWN', [34.2547, -89.8729, 98]), ('PSU', [40.72012, -77.93085, 376]), ('SXF', [43.73403, -96.62328, 473])])\n"
     ]
    }
   ],
   "source": [
    "print(stations.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "img = cv2.imread(\"ch1.png\")\n",
    "cv2.rectangle(img, (915-window_size, 401-window_size), (915+window_size, 401+window_size), (0,0,255), 2)\n",
    "cv2.putText(img,\"BND\",(915-15,401-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,255),1)\n",
    "\n",
    "cv2.rectangle(img, (878-window_size, 256-window_size), (878+window_size, 256+window_size), (0,255,0), 2)\n",
    "cv2.putText(img,\"GWN\",(878-15,256-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,255,0),1)\n",
    "\n",
    "cv2.rectangle(img, (494-window_size, 403-window_size), (494+window_size, 403+window_size), (0,150,150), 2)\n",
    "cv2.putText(img,\"TBL\",(494-15,403-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,150,150),1)\n",
    "\n",
    "cv2.rectangle(img, (224-window_size, 315-window_size), (224+window_size, 315+window_size), (0,255,255), 2)\n",
    "cv2.putText(img,\"DRA\",(224-15,315-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,255,255),1)\n",
    "\n",
    "cv2.rectangle(img, (497-window_size, 607-window_size), (497+window_size, 607+window_size), (255,255,0), 2)\n",
    "cv2.putText(img,\"FPK\",(497-15,607-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,0),1)\n",
    "\n",
    "cv2.rectangle(img, (1176-window_size, 418-window_size), (1176+window_size, 418+window_size), (255,0,255), 2)\n",
    "cv2.putText(img,\"PSU\",(1176-15,418-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,0,255),1)\n",
    "\n",
    "cv2.rectangle(img, (709-window_size, 493-window_size), (709+window_size, 493+window_size), (0,150,250), 2)\n",
    "cv2.putText(img,\"SXF\",(709-15,493-30),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,150,250),1)\n",
    "\n",
    "img = cv2.flip(img, 0)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"US_ch1.png\",img)\n",
    "cv2.imshow(\"US_ch1\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
